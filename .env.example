# =======================================================
# AI AGENT SYSTEM - ENVIRONMENT CONFIGURATION
# =======================================================

# ENVIRONMENT SETTINGS
# =======================================================
ENVIRONMENT=development
DEBUG=true
SECRET_KEY=your-super-secret-key-change-in-production-min-32-chars

# DATABASE CONFIGURATION
# =======================================================
# PostgreSQL Database
POSTGRES_DB=ai_agent_system
POSTGRES_USER=postgres
POSTGRES_PASSWORD=ai_agent_password
DATABASE_URL=postgresql://postgres:ai_agent_password@localhost:5432/ai_agent_system

# Development Database (override for dev)
POSTGRES_DB_DEV=ai_agent_system_dev
POSTGRES_PASSWORD_DEV=dev_password

# REDIS CONFIGURATION
# =======================================================
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=
REDIS_DB=0

# AI MODEL API KEYS
# =======================================================
# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_ORG_ID=your-openai-org-id-here
OPENAI_MODEL_DEFAULT=gpt-4
OPENAI_MAX_TOKENS=2048
OPENAI_TEMPERATURE=0.7

# Anthropic Claude Configuration (Sonnet 4)
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL_DEFAULT=claude-sonnet-4-20250514
ANTHROPIC_MAX_TOKENS=2048

# Google Gemini Configuration  
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_PROJECT_ID=your-google-project-id
GOOGLE_MODEL_DEFAULT=gemini-pro
GOOGLE_LOCATION=us-central1

# Hugging Face Configuration
HUGGINGFACE_API_KEY=your-huggingface-api-key-here
HUGGINGFACE_MODEL_DEFAULT=microsoft/DialoGPT-medium

# LOCAL LLM CONFIGURATION
# =======================================================
# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_HOST=0.0.0.0
OLLAMA_PORT=11434
OLLAMA_API_KEY=
OLLAMA_DEFAULT_MODEL=llama2
OLLAMA_FALLBACK_MODEL=codellama
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_MODELS_PATH=/usr/share/ollama/.ollama/models
OLLAMA_KEEP_ALIVE=24h
OLLAMA_NUM_CTX=4096
OLLAMA_NUM_PREDICT=512
OLLAMA_TEMPERATURE=0.7
OLLAMA_TOP_K=40
OLLAMA_TOP_P=0.9

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
OLLAMA_NUM_PARALLEL=1
OLLAMA_MAX_LOADED_MODELS=3
OLLAMA_GPU_MEMORY_FRACTION=0.8

# CORS AND SECURITY
# =======================================================
CORS_ORIGINS=["http://localhost:3000","http://127.0.0.1:3000","http://localhost:5173"]
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# MONITORING AND LOGGING
# =======================================================
# Grafana Configuration
GRAFANA_PASSWORD=admin
GRAFANA_USER=admin

# Prometheus Configuration
PROMETHEUS_RETENTION_TIME=200h

# Log Levels (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO
STRUCTURED_LOGGING=true

# PERFORMANCE SETTINGS
# =======================================================
# API Rate Limiting
RATE_LIMIT_PER_MINUTE=100
RATE_LIMIT_PER_HOUR=1000

# Connection Pool Settings
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30
DATABASE_POOL_TIMEOUT=30

# Redis Connection Pool
REDIS_POOL_SIZE=10
REDIS_POOL_TIMEOUT=20

# COST TRACKING AND OPTIMIZATION
# =======================================================
# Cost Management
MAX_DAILY_COST_USD=100.00
COST_ALERT_THRESHOLD_USD=50.00
ENABLE_COST_TRACKING=true

# Model Selection Strategy (cost_optimized, performance_optimized, balanced)
MODEL_SELECTION_STRATEGY=balanced

# LOCAL LLM FALLBACK SETTINGS
ENABLE_LOCAL_FALLBACK=true
LOCAL_FALLBACK_THRESHOLD_USD=10.00

# FILE UPLOAD AND STORAGE
# =======================================================
MAX_FILE_SIZE_MB=100
UPLOAD_PATH=/app/uploads
ALLOWED_FILE_TYPES=["txt","pdf","docx","csv","json","py","js","ts","md"]

# WEBSOCKET CONFIGURATION
# =======================================================
WEBSOCKET_TIMEOUT=300
WEBSOCKET_HEARTBEAT_INTERVAL=30
MAX_WEBSOCKET_CONNECTIONS=100

# CELERY BACKGROUND TASKS
# =======================================================
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2
CELERY_TASK_ALWAYS_EAGER=false

# DOCKER AND CONTAINER SETTINGS
# =======================================================
# Docker Configuration for Model Management
DOCKER_HOST=unix:///var/run/docker.sock
ENABLE_DOCKER_MANAGEMENT=true

# Resource Limits
MAX_MEMORY_USAGE_GB=8
MAX_CPU_CORES=4

# DEVELOPMENT SETTINGS
# =======================================================
# Only set these in development
RELOAD=true
DEBUG_TOOLBAR=true
PROFILING_ENABLED=false

# Test Database
TEST_DATABASE_URL=sqlite:///./test.db

# PRODUCTION OVERRIDES
# =======================================================
# Uncomment and modify for production deployment
# ENVIRONMENT=production
# DEBUG=false
# SECRET_KEY=your-production-secret-key-min-64-chars-very-secure
# DATABASE_URL=postgresql://prod_user:secure_password@prod_db:5432/ai_agent_prod
# REDIS_URL=redis://:secure_redis_password@prod_redis:6379
# CORS_ORIGINS=["https://yourdomain.com","https://www.yourdomain.com"]

# HEALTH CHECK ENDPOINTS
# =======================================================
HEALTH_CHECK_INTERVAL=30
HEALTH_CHECK_TIMEOUT=10
HEALTH_CHECK_RETRIES=3

# INTEGRATION TEST SETTINGS
# =======================================================
RUN_INTEGRATION_TESTS=true
TEST_TIMEOUT_SECONDS=60
SKIP_SLOW_TESTS=false
TEST_OLLAMA_MODELS=["llama2:7b","codellama:7b"]
TEST_DATABASE_URL=postgresql+asyncpg://postgres:ai_agent_password@localhost:5432/ai_agent_system_test
TEST_REDIS_URL=redis://localhost:6379/1
TEST_MAX_RETRIES=3

# Mock API Keys for Testing
TEST_OPENAI_API_KEY=test-openai-key
TEST_ANTHROPIC_API_KEY=test-anthropic-key
TEST_GOOGLE_API_KEY=test-google-key

# FRONTEND CONFIGURATION
# =======================================================
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000
VITE_APP_NAME=AI Agent System
VITE_APP_VERSION=1.0.0
VITE_ENVIRONMENT=development

# Frontend Feature Flags
VITE_ENABLE_ANALYTICS=true
VITE_ENABLE_LOCAL_MODELS=true
VITE_ENABLE_COST_TRACKING=true
VITE_ENABLE_DARK_MODE=true

# JWT CONFIGURATION
# =======================================================
JWT_SECRET_KEY=your-jwt-secret-key-here
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=30
JWT_REFRESH_EXPIRE_DAYS=7

# DOCKER RESOURCE LIMITS
# =======================================================
POSTGRES_MEMORY_LIMIT=1g
REDIS_MEMORY_LIMIT=512m
BACKEND_MEMORY_LIMIT=2g
FRONTEND_MEMORY_LIMIT=1g
OLLAMA_MEMORY_LIMIT=8g
PROMETHEUS_MEMORY_LIMIT=1g
GRAFANA_MEMORY_LIMIT=512m

# CPU Limits
POSTGRES_CPU_LIMIT=0.5
REDIS_CPU_LIMIT=0.25
BACKEND_CPU_LIMIT=1.0
FRONTEND_CPU_LIMIT=0.5
OLLAMA_CPU_LIMIT=2.0
PROMETHEUS_CPU_LIMIT=0.5
GRAFANA_CPU_LIMIT=0.25

# =======================================================
# ADVANCED CONFIGURATION SECTION
# =======================================================
# Add any additional environment variables below this section
# for easy modification and customization

# ADVANCED PERFORMANCE SETTINGS
# =======================================================
# Worker Configuration
WORKER_PROCESSES=4
WORKER_THREADS=2
WORKER_TIMEOUT=300
WORKER_MAX_REQUESTS=1000

# Connection Limits
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=60
KEEPALIVE_TIMEOUT=5

# Model Loading
MODEL_LOADING_TIMEOUT=300
MODEL_CACHE_SIZE=3
MODEL_MEMORY_LIMIT=8GB

# WEBSOCKET ADVANCED CONFIGURATION
# =======================================================
WS_MAX_CONNECTIONS=100
WS_PING_INTERVAL=30
WS_PING_TIMEOUT=10
WS_CLOSE_TIMEOUT=10
WS_MAX_MESSAGE_SIZE=1048576

# FILE UPLOAD AND STORAGE
# =======================================================
UPLOAD_MAX_FILE_SIZE=10485760
UPLOAD_ALLOWED_EXTENSIONS=txt,md,pdf,docx,json,csv
UPLOAD_PATH=./uploads
TEMP_PATH=./temp

# Storage Configuration
STORAGE_BACKEND=local
STORAGE_PATH=./storage
STORAGE_MAX_SIZE=1GB

# BACKUP AND RECOVERY
# =======================================================
BACKUP_ENABLED=false
BACKUP_SCHEDULE=0 2 * * *
BACKUP_RETENTION_DAYS=30
BACKUP_PATH=./backups

# Database Backup
DB_BACKUP_ENABLED=true
DB_BACKUP_SCHEDULE=0 3 * * *

# ADVANCED FEATURES
# =======================================================
# A/B Testing
ENABLE_AB_TESTING=false
AB_TEST_PERCENTAGE=10

# Analytics
ENABLE_ANALYTICS=true
ANALYTICS_ENDPOINT=http://localhost:8000/api/analytics

# Feature Flags
ENABLE_EXPERIMENTAL_FEATURES=false
ENABLE_BETA_FEATURES=true

# AUTO-OPTIMIZATION SETTINGS
# =======================================================
ENABLE_AUTO_MODEL_SELECTION=true
COST_OPTIMIZATION_THRESHOLD=0.01
PERFORMANCE_WEIGHT=0.7
COST_WEIGHT=0.3

# Model Cost Per Token (in USD)
OPENAI_COST_PER_1K_TOKENS=0.002
ANTHROPIC_COST_PER_1K_TOKENS=0.003
GOOGLE_COST_PER_1K_TOKENS=0.001
LOCAL_MODEL_COST_PER_1K_TOKENS=0.0001

# =======================================================
# NOTES:
# 1. Copy this file to .env and fill in your actual values
# 2. Never commit .env files to version control
# 3. Generate strong SECRET_KEY using: openssl rand -hex 32
# 4. For production, use strong passwords and secure API keys
# 5. Set ENVIRONMENT=production for production deployments
# 6. Modify the advanced configuration section above as needed
# =======================================================